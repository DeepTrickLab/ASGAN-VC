{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate speaker embeddings and metadata for training\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from factory.LstmDV import LstmDV\n",
    "#from factory.MetaDV import MetaDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C = MetaDV(80,256).to(device)\n",
    "C = LstmDV(80).to(device)\n",
    "C.load_state_dict(torch.load(\"../model/static/dv_vctk80.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW MANY DIFFERENT CONTENT OF VOICE IN YOUR DATA\n",
    "num_uttrs = 200\n",
    "errorment = 50\n",
    "len_crop = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory: ./train_spmel_vctk80\n"
     ]
    }
   ],
   "source": [
    "# Directory containing mel-spectrograms\n",
    "rootDir = './train_spmel_vctk80'\n",
    "dirName, subdirList, _ = next(os.walk(rootDir))\n",
    "print('Found directory: %s' % dirName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
    "    pad_size = target_length - array.shape[axis]\n",
    "    if pad_size <= 0:\n",
    "        return array\n",
    "    npad = [(0, 0)] * array.ndim\n",
    "    npad[axis] = (0, pad_size)\n",
    "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing speaker: p225\n",
      "Processing speaker: p226\n",
      "Processing speaker: p227\n",
      "Processing speaker: p228\n",
      "Processing speaker: p229\n",
      "Processing speaker: p230\n",
      "Processing speaker: p231\n",
      "Processing speaker: p232\n",
      "Processing speaker: p233\n",
      "Processing speaker: p234\n",
      "Processing speaker: p236\n",
      "Processing speaker: p237\n",
      "Processing speaker: p238\n",
      "Processing speaker: p239\n",
      "Processing speaker: p240\n",
      "Processing speaker: p241\n",
      "Processing speaker: p243\n",
      "Processing speaker: p244\n",
      "Processing speaker: p245\n",
      "Processing speaker: p246\n",
      "Processing speaker: p247\n",
      "Processing speaker: p248\n",
      "Processing speaker: p249\n",
      "Processing speaker: p250\n",
      "Processing speaker: p251\n",
      "Processing speaker: p252\n",
      "Processing speaker: p253\n",
      "Processing speaker: p254\n",
      "Processing speaker: p255\n",
      "Processing speaker: p256\n",
      "Processing speaker: p257\n",
      "Processing speaker: p258\n",
      "Processing speaker: p259\n",
      "Processing speaker: p260\n",
      "Processing speaker: p261\n",
      "Processing speaker: p262\n",
      "Processing speaker: p263\n",
      "Processing speaker: p264\n",
      "Processing speaker: p265\n",
      "Processing speaker: p266\n",
      "Processing speaker: p267\n",
      "Processing speaker: p268\n",
      "Processing speaker: p269\n",
      "Processing speaker: p270\n",
      "Processing speaker: p271\n",
      "Processing speaker: p272\n",
      "Processing speaker: p273\n",
      "Processing speaker: p274\n",
      "Processing speaker: p275\n",
      "Processing speaker: p276\n",
      "Processing speaker: p277\n",
      "Processing speaker: p278\n",
      "Processing speaker: p279\n",
      "Processing speaker: p280\n",
      "Processing speaker: p281\n",
      "Processing speaker: p282\n",
      "Processing speaker: p283\n",
      "Processing speaker: p284\n",
      "Processing speaker: p285\n",
      "Processing speaker: p286\n",
      "Processing speaker: p287\n",
      "Processing speaker: p288\n",
      "Processing speaker: p292\n",
      "Processing speaker: p293\n",
      "Processing speaker: p294\n",
      "Processing speaker: p295\n",
      "(14, 80)\n",
      "(44, 80)\n",
      "Processing speaker: p297\n",
      "Processing speaker: p298\n",
      "Processing speaker: p299\n",
      "Processing speaker: p300\n",
      "Processing speaker: p301\n",
      "Processing speaker: p302\n",
      "(99, 80)\n",
      "Processing speaker: p303\n",
      "Processing speaker: p304\n",
      "Processing speaker: p305\n",
      "(25, 80)\n",
      "Processing speaker: p306\n",
      "(73, 80)\n",
      "Processing speaker: p307\n",
      "Processing speaker: p308\n",
      "Processing speaker: p310\n",
      "Processing speaker: p311\n"
     ]
    }
   ],
   "source": [
    "speakers = []\n",
    "for speaker in sorted(subdirList):\n",
    "    print('Processing speaker: %s' % speaker)\n",
    "    utterances,embs  = [],[]\n",
    "    utterances.append(speaker)\n",
    "    _, _, fileList = next(os.walk(os.path.join(dirName,speaker)))\n",
    "    # make speaker embedding\n",
    "    assert len(fileList) >= num_uttrs\n",
    "    idx_uttrs = np.random.choice(len(fileList), size=num_uttrs, replace=False)\n",
    "    for i in range(errorment):\n",
    "        tmp = np.load(os.path.join(dirName, speaker, fileList[idx_uttrs[i]]))\n",
    "        # pad if the current one is too short   \n",
    "        if tmp.shape[0] < len_crop:\n",
    "            tmp = pad_along_axis(tmp,len_crop)\n",
    "            melsp = torch.from_numpy(tmp[np.newaxis,:, :]).cuda()\n",
    "        else:\n",
    "            melsp = torch.from_numpy(tmp[np.newaxis,:, :]).cuda()\n",
    "        emb = C(melsp)[1]\n",
    "        embs.append(emb.detach().squeeze().cpu().numpy())    \n",
    "           \n",
    "    utterances.append(np.mean(embs, axis=0))\n",
    "    # create file list\n",
    "    want_uttr = 0\n",
    "    for fileName in sorted(fileList):\n",
    "        tmp = np.load(os.path.join(dirName, speaker,fileName))\n",
    "        # 不足 100 的丟掉\n",
    "        if tmp.shape[0] < 100:\n",
    "            print(tmp.shape)\n",
    "            continue\n",
    "        elif want_uttr < num_uttrs:\n",
    "            utterances.append(os.path.join(speaker,fileName))\n",
    "            want_uttr += 1\n",
    "        else:\n",
    "            continue\n",
    "    speakers.append(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(rootDir, 'train_lstm.pkl'), 'wb') as handle:\n",
    "    pickle.dump(speakers, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
