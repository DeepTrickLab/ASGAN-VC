{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "from thirdparty.DeepSpeaker.util.audio import read_mfcc,get_mfcc_from_wave\n",
    "from thirdparty.DeepSpeaker.util.batcher import sample_from_mfcc\n",
    "from thirdparty.DeepSpeaker.util.constants import SAMPLE_RATE, NUM_FRAMES\n",
    "from thirdparty.DeepSpeaker.util.conv_models import DeepSpeakerModel\n",
    "from thirdparty.DeepSpeaker.util.test import batch_cosine_similarity\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSpeakerModel()\n",
    "model.m.load_weights(f'thirdparty/DeepSpeaker/model/ResCNN_triplet_training_checkpoint_265.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_speaker = 80\n",
    "erroment_num = 16\n",
    "num_uttrs = 99\n",
    "device = \"cuda:0\"\n",
    "ROOT = 'train_wave_vctk80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speaker = next(iter(os.walk(ROOT)))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(num_uttrs, rootDir):\n",
    "    dirName, subdirList, _ = next(os.walk(rootDir))\n",
    "    print(f\"Found directory: {dirName}\")\n",
    "    data_dict = {}\n",
    "    for j, speaker in enumerate(sorted(subdirList)):\n",
    "        print(\"Processing speaker: %s\" % speaker)\n",
    "        _, _, fileList = next(os.walk(os.path.join(dirName, speaker)))\n",
    "        fileList = fileList[:num_uttrs]\n",
    "        all_data = []\n",
    "        for file in fileList:\n",
    "            path = os.path.join(dirName, speaker, file)\n",
    "            mfcc = sample_from_mfcc(read_mfcc(path, SAMPLE_RATE), NUM_FRAMES)\n",
    "            all_data.append(mfcc)\n",
    "        data_dict[speaker] = all_data\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory: train_wave_vctk80\n",
      "Processing speaker: p225\n",
      "Processing speaker: p226\n",
      "Processing speaker: p227\n",
      "Processing speaker: p228\n",
      "Processing speaker: p229\n",
      "Processing speaker: p230\n",
      "Processing speaker: p231\n",
      "Processing speaker: p232\n",
      "Processing speaker: p233\n",
      "Processing speaker: p234\n",
      "Processing speaker: p236\n",
      "Processing speaker: p237\n",
      "Processing speaker: p238\n",
      "Processing speaker: p239\n",
      "Processing speaker: p240\n",
      "Processing speaker: p241\n",
      "Processing speaker: p243\n",
      "Processing speaker: p244\n",
      "Processing speaker: p245\n",
      "Processing speaker: p246\n",
      "Processing speaker: p247\n",
      "Processing speaker: p248\n",
      "Processing speaker: p249\n",
      "Processing speaker: p250\n",
      "Processing speaker: p251\n",
      "Processing speaker: p252\n",
      "Processing speaker: p253\n",
      "Processing speaker: p254\n",
      "Processing speaker: p255\n",
      "Processing speaker: p256\n",
      "Processing speaker: p257\n",
      "Processing speaker: p258\n",
      "Processing speaker: p259\n",
      "Processing speaker: p260\n",
      "Processing speaker: p261\n",
      "Processing speaker: p262\n",
      "Processing speaker: p263\n",
      "Processing speaker: p264\n",
      "Processing speaker: p265\n",
      "Processing speaker: p266\n",
      "Processing speaker: p267\n",
      "Processing speaker: p268\n",
      "Processing speaker: p269\n",
      "Processing speaker: p270\n",
      "Processing speaker: p271\n",
      "Processing speaker: p272\n",
      "Processing speaker: p273\n",
      "Processing speaker: p274\n",
      "Processing speaker: p275\n",
      "Processing speaker: p276\n",
      "Processing speaker: p277\n",
      "Processing speaker: p278\n",
      "Processing speaker: p279\n",
      "Processing speaker: p280\n",
      "Processing speaker: p281\n",
      "Processing speaker: p282\n",
      "Processing speaker: p283\n",
      "Processing speaker: p284\n",
      "Processing speaker: p285\n",
      "Processing speaker: p286\n",
      "Processing speaker: p287\n",
      "Processing speaker: p288\n",
      "Processing speaker: p292\n",
      "Processing speaker: p293\n",
      "Processing speaker: p294\n",
      "Processing speaker: p295\n",
      "Processing speaker: p297\n",
      "Processing speaker: p298\n",
      "Processing speaker: p299\n",
      "Processing speaker: p300\n",
      "Processing speaker: p301\n",
      "Processing speaker: p302\n",
      "Processing speaker: p303\n",
      "Processing speaker: p304\n",
      "Processing speaker: p305\n",
      "Processing speaker: p306\n",
      "Processing speaker: p307\n",
      "Processing speaker: p308\n",
      "Processing speaker: p310\n",
      "Processing speaker: p311\n"
     ]
    }
   ],
   "source": [
    "data_dict = generate_dataset(num_uttrs,ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truth_dv(enrollment_mfcc):\n",
    "    _dv = np.zeros((1, 512))\n",
    "    for mfcc in enrollment_mfcc:\n",
    "        _dv += model.m.predict(np.expand_dims(mfcc, axis=0)) \n",
    "    return (_dv / erroment_num).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_cos(all_dv,enrroment_idxs):\n",
    "    cos_result = np.zeros((num_speaker, num_speaker))\n",
    "    var_result = np.zeros((num_speaker, num_speaker))\n",
    "    for i,key in enumerate(data_dict.keys()):\n",
    "        # Generate embed from remain idx\n",
    "        tmp_style = []\n",
    "        print(f\"Now process --- {key}\")\n",
    "        all_mfcc = data_dict[key]\n",
    "        for j in range(num_uttrs):\n",
    "            if j not in enrroment_idxs:\n",
    "                mfcc = all_mfcc[j]\n",
    "                tmp_style.append(model.m.predict(np.expand_dims(mfcc, axis=0)).reshape(-1))\n",
    "\n",
    "        # Compare with all truth dv\n",
    "        for k,dv in enumerate(all_dv):\n",
    "            tmp_cos = []\n",
    "            for _style in tmp_style:\n",
    "                cos_ = np.dot(dv,_style) / (np.linalg.norm(dv) * np.linalg.norm(_style))\n",
    "                tmp_cos.append(cos_)\n",
    "\n",
    "            cos_result[i][k] = np.array(tmp_cos).mean()\n",
    "            var_result[i][k] = np.array(tmp_cos).std()\n",
    "    return cos_result, var_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ytrue_yscore(cos_res):\n",
    "        N = len(cos_res)\n",
    "        y_true, y_score = [], []\n",
    "        for i in range(N):\n",
    "            for ele in np.diagonal(cos_res[i]):\n",
    "                y_score.append(ele)\n",
    "            for _ in range(len(cos_res[i])):\n",
    "                y_true.append(1)\n",
    "            # remove diagonal element\n",
    "            m = cos_res[i].shape[0]\n",
    "            strided = np.lib.stride_tricks.as_strided\n",
    "            s0, s1 = cos_res[i].strides\n",
    "            outs = (\n",
    "                strided(cos_res[i].ravel()[1:], shape=(m - 1, m), strides=(s0 + s1, s1))\n",
    "                .reshape(m, -1)\n",
    "                .flatten()\n",
    "            )\n",
    "            for ele in outs:\n",
    "                y_score.append(ele)\n",
    "            for _ in range(len(outs)):\n",
    "                y_true.append(0)\n",
    "        return y_true, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate truth_dv --- done\n",
      "Now process --- p225\n",
      "Now process --- p226\n",
      "Now process --- p227\n",
      "Now process --- p228\n",
      "Now process --- p229\n",
      "Now process --- p230\n",
      "Now process --- p231\n",
      "Now process --- p232\n",
      "Now process --- p233\n",
      "Now process --- p234\n",
      "Now process --- p236\n",
      "Now process --- p237\n",
      "Now process --- p238\n",
      "Now process --- p239\n",
      "Now process --- p240\n",
      "Now process --- p241\n",
      "Now process --- p243\n",
      "Now process --- p244\n",
      "Now process --- p245\n",
      "Now process --- p246\n",
      "Now process --- p247\n",
      "Now process --- p248\n",
      "Now process --- p249\n",
      "Now process --- p250\n",
      "Now process --- p251\n",
      "Now process --- p252\n",
      "Now process --- p253\n",
      "Now process --- p254\n",
      "Now process --- p255\n",
      "Now process --- p256\n",
      "Now process --- p257\n",
      "Now process --- p258\n",
      "Now process --- p259\n",
      "Now process --- p260\n",
      "Now process --- p261\n",
      "Now process --- p262\n",
      "Now process --- p263\n",
      "Now process --- p264\n",
      "Now process --- p265\n",
      "Now process --- p266\n",
      "Now process --- p267\n",
      "Now process --- p268\n",
      "Now process --- p269\n",
      "Now process --- p270\n",
      "Now process --- p271\n",
      "Now process --- p272\n",
      "Now process --- p273\n",
      "Now process --- p274\n",
      "Now process --- p275\n",
      "Now process --- p276\n",
      "Now process --- p277\n",
      "Now process --- p278\n",
      "Now process --- p279\n",
      "Now process --- p280\n",
      "Now process --- p281\n",
      "Now process --- p282\n",
      "Now process --- p283\n",
      "Now process --- p284\n",
      "Now process --- p285\n",
      "Now process --- p286\n",
      "Now process --- p287\n",
      "Now process --- p288\n",
      "Now process --- p292\n",
      "Now process --- p293\n",
      "Now process --- p294\n",
      "Now process --- p295\n",
      "Now process --- p297\n",
      "Now process --- p298\n",
      "Now process --- p299\n",
      "Now process --- p300\n",
      "Now process --- p301\n",
      "Now process --- p302\n",
      "Now process --- p303\n",
      "Now process --- p304\n",
      "Now process --- p305\n",
      "Now process --- p306\n",
      "Now process --- p307\n",
      "Now process --- p308\n",
      "Now process --- p310\n",
      "Now process --- p311\n"
     ]
    }
   ],
   "source": [
    "all_real_cos_result = []\n",
    "all_real_var_result = [] \n",
    "all_non_real_cos_result = []\n",
    "all_non_real_var_result = []\n",
    "all_yt, all_ys = [],[]\n",
    "for i in range(1):\n",
    "    all_dv,enrroment_idxs = [],[]\n",
    "    for _ in range(erroment_num):\n",
    "        enrroment_idxs.append(random.randint(0,1))\n",
    "        \n",
    "    # Generate truth embed\n",
    "    for key in data_dict.keys():\n",
    "        #print(f\"Now process --- {key}\")\n",
    "        all_mfcc = data_dict[key]\n",
    "        enrollment_mfcc = []\n",
    "        for enrroment_idx in enrroment_idxs:\n",
    "            enrollment_mfcc.append(all_mfcc[enrroment_idx])\n",
    "        all_dv.append(get_truth_dv(enrollment_mfcc))\n",
    "    print(f\"Generate truth_dv --- done\")\n",
    "    real_cos_result, real_var_result = generate_real_cos(all_dv,enrroment_idxs)\n",
    "    \n",
    "    y_true, y_score = get_ytrue_yscore([real_cos_result])\n",
    "    for ele in y_true:\n",
    "        all_yt.append(ele)\n",
    "    for ele in y_score:\n",
    "        all_ys.append(ele)\n",
    "    ## Mean of 40 speaker Cos-similarity\n",
    "    all_real_cos_result.append(np.diagonal(real_cos_result).mean())\n",
    "    ## Mean of 40 speaker Cos-similarity Variance\n",
    "    all_real_var_result.append(np.diagonal(real_var_result).mean())\n",
    "    ##  Mean of 40 speaker Cos-similarity with non_source speaker embedding\n",
    "    all_non_real_cos_result.append((np.sum(real_cos_result) - (np.sum(np.diagonal(real_cos_result)))) /(num_speaker*(num_speaker-1)))\n",
    "    ##  Mean of 40 speaker Cos-similarity Variance with non_source speaker embedding\n",
    "    all_non_real_var_result.append((np.sum(real_var_result) - (np.sum(np.diagonal(real_var_result)))) /(num_speaker*(num_speaker-1)))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911036392405064"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7456258727690876, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_real_cos_result).mean(),np.array(all_real_cos_result).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.40959155662053015, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_non_real_cos_result).mean(),np.array(all_non_real_cos_result).std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
